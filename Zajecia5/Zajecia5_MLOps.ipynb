{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ed90eb",
   "metadata": {},
   "source": [
    "# Class 5 - Machine Learning Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b6b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e25bcc",
   "metadata": {},
   "source": [
    "**Load dataset - Boston housing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74048ff",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "- **CRIM**     - per capita crime rate by town\n",
    "- **ZN**       - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- **INDUS**   -  proportion of non-retail business acres per town\n",
    "- **CHAS**     - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- **NOX**     - nitric oxides concentration (parts per 10 million)\n",
    "- **RM**      - average number of rooms per dwelling\n",
    "- **AGE**     -  proportion of owner-occupied units built prior to 1940\n",
    "- **DIS**     -  weighted distances to five Boston employment centres\n",
    "- **RAD**      - index of accessibility to radial highways\n",
    "- **TAX**      - full-value property-tax rate per \\$10,000\n",
    "- **PTRATIO** -  pupil-teacher ratio by town\n",
    "- **B**       -  1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- **LSTAT**   -  % lower status of the population\n",
    "- **MEDV**    -  Median value of owner-occupied homes in \\$1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b9f90c",
   "metadata": {},
   "source": [
    "**Task:** Regression of target feature `MEDV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv(\"Boston.csv\").drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d0a83",
   "metadata": {},
   "source": [
    "Splitting data into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0353954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.drop(columns='medv')\n",
    "y = boston['medv']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819e061",
   "metadata": {},
   "source": [
    "Training neural network with one hidden layer and ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0187b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[X.shape[1]]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "#Optimizing for Mean Square Error (MSE)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "#Early stopping may be considered as a regularization\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "training_record = model.fit(X_train,\n",
    "                       y_train,\n",
    "                       epochs=10,\n",
    "                       validation_split=0.3,\n",
    "                       verbose=1,\n",
    "                       callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a80309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(training_record.history)\n",
    "df['epoch'] = training_record.epoch\n",
    "plt.figure(figsize=[15,8])\n",
    "plt.plot(df['epoch'], df['mse'], label='Train')\n",
    "plt.plot(df['epoch'], df['val_mse'], label = 'Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_quality(y_true, y_pred):\n",
    "    print(f\"Model RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.3f} (mean test y: {np.mean(y_true):.3f})\")\n",
    "    print(f\"Model R^2: {r2_score(y_true, y_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319618ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "model_quality(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71491be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for deployment\n",
    "model.save('Boston_NN.keras')\n",
    "shutil.copyfile('Boston_NN.keras', 'keras-app/Boston_NN.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0467a9",
   "metadata": {},
   "source": [
    "## Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    global model\n",
    "    model = tensorflow.keras.models.load_model('Boston_NN.keras')\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"\"\"This is Boston prediction app. Use <b>/predict</b> endpoint with POST request e.g. <br><br> \n",
    "    curl -X POST -F data=@house.json 'http://localhost:5000/predict'\"\"\"\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "    if flask.request.method == \"POST\":\n",
    "        if flask.request.files.get(\"data\"):\n",
    "            observation = pd.read_json(flask.request.files[\"data\"], orient='index').transpose()\n",
    "            data[\"prediction\"] = np.float64(model.predict(observation, verbose=0)[0][0])\n",
    "            data[\"success\"] = True\n",
    "\n",
    "    return flask.jsonify(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"* Loading Keras model and Flask server...\")\n",
    "    load_model()\n",
    "    app.run(host='0.0.0.0', threaded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b90d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!curl -X POST -F data=@house.json http://localhost:5000/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb82583",
   "metadata": {},
   "source": [
    "The app can also be launched in terminal by switching working directory to `keras-app` folder and running\n",
    "```shell\n",
    "python app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae303de",
   "metadata": {},
   "source": [
    "We have an app ready to be published - right now we can only access our ML service locally, so it's still not very useful. The `app.py` can be deployed on a remote machine with the public IP and after binding DNS domain with the IP, the service could be available under a nice URL like http://boston-predict.com/. \n",
    "\n",
    "The server would require the setup of all dependencies and correct configuration, so there is additional effort to operationalize the app. With that approach scaling the service and applying changes (maybe next step is to add a graphical interface) would also be very tedious. Some of the problems can be alleviated by packaging the app into container such as [Docker container](https://www.docker.com/). Containerization is a modern technique for applications development - the application source code, configuration and all required dependencies are packed within an image which can be easily shared and run on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc81e7",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd keras-app\n",
    "docker build -t boston-app .\n",
    "docker run -d -p 5000:5000 boston-app\n",
    "docker ps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a19be",
   "metadata": {},
   "source": [
    "In particular, containers can be run on public cloud services such as [Cloud Run](https://cloud.google.com/run) - the managed services make it easier to monitor and maintain the ML applications. First image created in previous step is uploaded to [Container Registry](https://cloud.google.com/artifact-registry/docs) and launched as through Cloud Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cad8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -F data=@house.json https://boston-app-t6lyhjuhjq-lm.a.run.app/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4643fe3",
   "metadata": {},
   "source": [
    "## Model maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31388a14",
   "metadata": {},
   "source": [
    "After deploying the model, the maintanance and monitoring phase starts. From the technical perspective, the application need to handle all the incoming requests within reasonable time, provide appropiate error handling, stay stable within the normal usage, etc. \n",
    "\n",
    "Additionally, the model needs to be monitored with regard to predictive performance. The drift in the incoming data (changes in the distribution of the underlying features compared to the training dataset) may degrade the model's quality. The bussiness needs may change over time as well, which in some cases may require model retraining or redefinition of the task.\n",
    "\n",
    "In more complex deployments, multiple models are involved in the monitoring and maintance process. Usually the setup includes the 'leading' model and 'auxilary' models. Commonly used techniques include:\n",
    "* **champion-challenger approach** - the 'champion' model is serving the predictions as the best performing model and the model's quality metrics are gathered over time; periodically the 'challengers' are evaluated against the new data points; if a challanger scores better than the champion, it may replace it as a new champion and the process is continued\n",
    "* **multi-armed bandits** - there are multiple models capable of serving the prediction in the deployed solution; the leading model in terms of predictive quality handles more requests than the remaining models; often each model receives the probability of serving the prediction, where the leading model has the highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd402431",
   "metadata": {},
   "source": [
    "**Multi-armed bandit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f822cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_lr = LR().fit(X_train, y_train)\n",
    "model_quality(y_test, boston_lr.predict(X_test))\n",
    "with open('Boston_LR.pkl', 'wb') as f:\n",
    "    pickle.dump(boston_lr, f)\n",
    "shutil.copyfile('Boston_LR.pkl', 'keras-app/Boston_LR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dtr = DTR().fit(X_train, y_train)\n",
    "model_quality(y_test, boston_dtr.predict(X_test))\n",
    "with open('Boston_DTR.pkl', 'wb') as f:\n",
    "    pickle.dump(boston_dtr, f)\n",
    "shutil.copyfile('Boston_DTR.pkl', 'keras-app/Boston_DTR.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537adcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    global model_nn\n",
    "    model_nn = tensorflow.keras.models.load_model('Boston_NN.keras')\n",
    "    global model_lr\n",
    "    with open('Boston_LR.pkl', 'rb') as f:\n",
    "        model_lr = pickle.load(f)\n",
    "    global model_dtr\n",
    "    with open('Boston_DTR.pkl', 'rb') as f:\n",
    "        model_dtr = pickle.load(f)\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"\"\"This is Boston prediction app. Use <b>/predict</b> endpoint with POST request e.g. <br><br> \n",
    "    curl -X POST -F data=@house.json 'http://localhost:5000/predict'\"\"\"\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    epsilon = 0.8\n",
    "    bandits = [(\"Neural Network\", model_nn), (\"Linear Regression\", model_lr),\n",
    "               (\"Decision Tree\", model_dtr)]\n",
    "    pick_probs = np.arange(epsilon, 1.0001, (1 - epsilon) / (len(bandits) - 1))\n",
    "    pick = np.random.rand()\n",
    "    index = sum([e < pick for e in pick_probs])\n",
    "    model_name, model = bandits[index]\n",
    "    data = {\"success\": False}\n",
    "    if flask.request.method == \"POST\":\n",
    "        if flask.request.files.get(\"data\"):\n",
    "            observation = pd.read_json(flask.request.files[\"data\"],\n",
    "                                       orient='index').transpose()\n",
    "            if model_name == \"Neural Network\":\n",
    "                data[\"prediction\"] = np.float64(\n",
    "                    model.predict(observation, verbose=0)[0][0])\n",
    "            else:\n",
    "                data[\"prediction\"] = model.predict(observation)[0]\n",
    "            data[\"model\"] = model_name\n",
    "            data[\"success\"] = True\n",
    "\n",
    "    return flask.jsonify(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"* Loading Keras model and Flask server...\")\n",
    "    load_models()\n",
    "    app.run(host='0.0.0.0', threaded=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7caa1",
   "metadata": {},
   "source": [
    "Validating proportions of models in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcfc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70370c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_response = []\n",
    "with open('house.json', 'r') as f:\n",
    "    files = {'data': f.read()}\n",
    "n = 100\n",
    "for _ in tqdm(range(n)):\n",
    "    res = requests.post('http://localhost:5000/predict', files=files)\n",
    "    models_response.append(json.loads(res.content)['model'])\n",
    "models_count = np.unique(np.array(models_response), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab68be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.bar(*models_count, color=['r', 'g', 'b'])\n",
    "plt.ylabel(\"Frequency\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
